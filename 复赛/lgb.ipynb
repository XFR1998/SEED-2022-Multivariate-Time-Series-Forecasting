{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import pdb\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 禁止hash随机化\n",
    "\n",
    "set_seed(42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# label: '推料器自动指令'\n",
    "# train_data_path = './data/train/'\n",
    "# test_data_path = './data/test/'\n",
    "#\n",
    "# train_cols = ['推料器自动指令', 'CO含量', 'HCL含量', 'NOx含量', 'SO2含量', '二次风调门', '二次风量', '给水流量',\n",
    "#         '炉排实际运行指令', '炉排自动投退信号', '汽包水位', '推料器启停', '推料器自动投退信号',\n",
    "#         '氧量设定值', '一次风调门', '一次风量', '引风机转速', '主蒸汽流量']\n",
    "#\n",
    "# test_cols = ['CO含量', 'HCL含量', 'NOx含量', 'SO2含量', '二次风调门', '二次风量', '给水流量',\n",
    "#         '炉排实际运行指令', '炉排自动投退信号', '汽包水位', '推料器启停', '推料器自动投退信号',\n",
    "#         '氧量设定值', '一次风调门', '一次风量', '引风机转速', '主蒸汽流量']\n",
    "#\n",
    "# print(len(train_cols))\n",
    "# print(len(test_cols))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# train_df = pd.DataFrame()\n",
    "# train_df['时间'] = pd.read_csv(train_data_path+'CO含量.csv')['时间']\n",
    "#\n",
    "# for n in tqdm(train_cols):\n",
    "#     train_df[n] = pd.read_csv(train_data_path+f'{n}.csv')[n]\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame()\n",
    "# test_df['时间'] = pd.read_csv(test_data_path+'CO含量.csv')['时间']\n",
    "#\n",
    "# for n in tqdm(test_cols):\n",
    "#     test_df[n] = pd.read_csv(test_data_path+f'{n}.csv')[n]\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# # 有重复的行，需要去重\n",
    "# print('训练集中重复的行数：', train_df.duplicated().sum())\n",
    "# train_df = train_df.drop_duplicates()\n",
    "#\n",
    "# print('测试集中重复的行数：', test_df.duplicated().sum())\n",
    "# test_df = test_df.drop_duplicates()\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# train_df.to_csv('./data/train.csv', index=False)\n",
    "# test_df.to_csv('./data/test.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 141188 entries, 0 to 141187\n",
      "Data columns (total 19 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   时间         141188 non-null  object \n",
      " 1   推料器自动指令    141188 non-null  float64\n",
      " 2   CO含量       141188 non-null  float64\n",
      " 3   HCL含量      141188 non-null  float64\n",
      " 4   NOx含量      141188 non-null  float64\n",
      " 5   SO2含量      141188 non-null  float64\n",
      " 6   二次风调门      141188 non-null  float64\n",
      " 7   二次风量       141188 non-null  float64\n",
      " 8   给水流量       141188 non-null  float64\n",
      " 9   炉排实际运行指令   141188 non-null  float64\n",
      " 10  炉排自动投退信号   141188 non-null  object \n",
      " 11  汽包水位       141188 non-null  float64\n",
      " 12  推料器启停      141188 non-null  object \n",
      " 13  推料器自动投退信号  141188 non-null  object \n",
      " 14  氧量设定值      141188 non-null  float64\n",
      " 15  一次风调门      141188 non-null  float64\n",
      " 16  一次风量       141188 non-null  float64\n",
      " 17  引风机转速      141188 non-null  float64\n",
      " 18  主蒸汽流量      141188 non-null  float64\n",
      "dtypes: float64(15), object(4)\n",
      "memory usage: 21.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   时间         1800 non-null   object \n",
      " 1   CO含量       1800 non-null   float64\n",
      " 2   HCL含量      1800 non-null   float64\n",
      " 3   NOx含量      1800 non-null   float64\n",
      " 4   SO2含量      1800 non-null   float64\n",
      " 5   二次风调门      1800 non-null   float64\n",
      " 6   二次风量       1800 non-null   float64\n",
      " 7   给水流量       1800 non-null   float64\n",
      " 8   炉排实际运行指令   1800 non-null   float64\n",
      " 9   炉排自动投退信号   1800 non-null   bool   \n",
      " 10  汽包水位       1800 non-null   float64\n",
      " 11  推料器启停      1800 non-null   bool   \n",
      " 12  推料器自动投退信号  1800 non-null   bool   \n",
      " 13  氧量设定值      1800 non-null   float64\n",
      " 14  一次风调门      1800 non-null   float64\n",
      " 15  一次风量       1800 non-null   float64\n",
      " 16  引风机转速      1800 non-null   float64\n",
      " 17  主蒸汽流量      1800 non-null   float64\n",
      "dtypes: bool(3), float64(14), object(1)\n",
      "memory usage: 216.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "train_df.info()\n",
    "test_df.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142988 entries, 0 to 1799\n",
      "Data columns (total 19 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   时间         142988 non-null  object \n",
      " 1   推料器自动指令    141188 non-null  float64\n",
      " 2   CO含量       142988 non-null  float64\n",
      " 3   HCL含量      142988 non-null  float64\n",
      " 4   NOx含量      142988 non-null  float64\n",
      " 5   SO2含量      142988 non-null  float64\n",
      " 6   二次风调门      142988 non-null  float64\n",
      " 7   二次风量       142988 non-null  float64\n",
      " 8   给水流量       142988 non-null  float64\n",
      " 9   炉排实际运行指令   142988 non-null  float64\n",
      " 10  炉排自动投退信号   142988 non-null  object \n",
      " 11  汽包水位       142988 non-null  float64\n",
      " 12  推料器启停      142988 non-null  object \n",
      " 13  推料器自动投退信号  142988 non-null  object \n",
      " 14  氧量设定值      142988 non-null  float64\n",
      " 15  一次风调门      142988 non-null  float64\n",
      " 16  一次风量       142988 non-null  float64\n",
      " 17  引风机转速      142988 non-null  float64\n",
      " 18  主蒸汽流量      142988 non-null  float64\n",
      "dtypes: float64(15), object(4)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train_df, test_df])\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True     102060\nFalse     40928\nName: 推料器启停, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['推料器启停'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data = data[data['推料器启停']==1]\n",
    "# data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 102060 entries, 169 to 1799\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   时间         102060 non-null  object \n",
      " 1   推料器自动指令    100260 non-null  float64\n",
      " 2   CO含量       102060 non-null  float64\n",
      " 3   HCL含量      102060 non-null  float64\n",
      " 4   NOx含量      102060 non-null  float64\n",
      " 5   SO2含量      102060 non-null  float64\n",
      " 6   二次风调门      102060 non-null  float64\n",
      " 7   二次风量       102060 non-null  float64\n",
      " 8   给水流量       102060 non-null  float64\n",
      " 9   炉排实际运行指令   102060 non-null  float64\n",
      " 10  炉排自动投退信号   102060 non-null  object \n",
      " 11  汽包水位       102060 non-null  float64\n",
      " 12  推料器自动投退信号  102060 non-null  object \n",
      " 13  氧量设定值      102060 non-null  float64\n",
      " 14  一次风调门      102060 non-null  float64\n",
      " 15  一次风量       102060 non-null  float64\n",
      " 16  引风机转速      102060 non-null  float64\n",
      " 17  主蒸汽流量      102060 non-null  float64\n",
      "dtypes: float64(15), object(3)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['推料器启停'])\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:17<00:00,  5.19s/it]\n"
     ]
    }
   ],
   "source": [
    "data['gas'] = data['CO含量'] + data['HCL含量'] + data['NOx含量'] + data['SO2含量']\n",
    "# feat_list = ['二次风调门', '二次风量', '给水流量', '炉排实际运行指令', '汽包水位', '氧量设定值', '一次风调门', '一次风量', '引风机转速', '主蒸汽流量']\n",
    "# ['给水流量', '氧量设定值', '一次风量', '主蒸汽流量', '汽包水位']\n",
    "feat_list = ['炉排实际运行指令','gas','CO含量','HCL含量','NOx含量','SO2含量','二次风调门', '二次风量', '给水流量', '汽包水位', '氧量设定值', '一次风调门', '一次风量', '引风机转速', '主蒸汽流量']\n",
    "for f in tqdm(feat_list):\n",
    "    shift_f = []\n",
    "    shift_lf = []\n",
    "    shift_d = []\n",
    "    for i in range(200):\n",
    "        colname = f + '_shift_{}'.format(i + 1)\n",
    "        data[colname] = data[f].shift(i + 1)\n",
    "        shift_f.append(colname)\n",
    "\n",
    "        colname = f + '_lshift_{}'.format(-(i + 1))\n",
    "        data[colname] = data[f].shift(-(i + 1))\n",
    "        shift_lf.append(colname)\n",
    " \n",
    "        # .diff用于计算一列中某元素与该列中前？个元素的差值（默认前一个元素）\n",
    "        # colname = f + '_diff_{}'.format(i + 1)\n",
    "        # data[colname] = data[f].diff(i + 1)\n",
    "        # colname = f + '_diff_{}'.format(-(i + 1))\n",
    "        # data[colname] = data[f].diff(-(i + 1))\n",
    "\n",
    "    # data[f+'_diff'] = data[f].diff(1)\n",
    "    # 对每一行：shift_列的值取平均，即将前n天的值取平均，取最大值，最最小值，最标准差\n",
    "\n",
    "    data[f + '_fore_steps_mean'] = data[shift_f].mean(1)\n",
    "    data[f + '_fore_steps_max'] = data[shift_f].max(1)\n",
    "    data[f + '_fore_steps_min'] = data[shift_f].min(1)\n",
    "    data[f + '_fore_steps_std'] = data[shift_f].std(1)\n",
    "    data[f + '_fore_steps_std'] = data[shift_f].skew(1)\n",
    "\n",
    "    data[f + '_lfore_steps_mean'] = data[shift_lf].mean(1)\n",
    "    data[f + '_lfore_steps_max'] = data[shift_lf].max(1)\n",
    "    data[f + '_lfore_steps_min'] = data[shift_lf].min(1)\n",
    "    data[f + '_lfore_steps_std'] = data[shift_lf].std(1)\n",
    "    data[f + '_lfore_steps_std'] = data[shift_lf].skew(1)\n",
    "\n",
    "    data.drop(shift_f, axis=1, inplace=True)\n",
    "    data.drop(shift_lf, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#\n",
    "data['炉排自动投退信号'] = data['炉排自动投退信号'].map(int)\n",
    "# data['推料器启停'] = data['推料器启停'].map(int)\n",
    "data['推料器自动投退信号'] = data['推料器自动投退信号'].map(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# import pandas as pd\n",
    "# import featuretools as ft\n",
    "#\n",
    "# # Load data and put into dataframe\n",
    "# iris = load_iris()\n",
    "# df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "# df['species'] = iris.target\n",
    "# df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# # Make an entityset and add the entity\n",
    "# es = ft.EntitySet(id = 'iris')\n",
    "# es.add_dataframe(dataframe_name = 'data', dataframe = df,\n",
    "#                          make_index = True, index = 'index')\n",
    "#\n",
    "# # Run deep feature synthesis with transformation primitives\n",
    "# feature_matrix, feature_defs = ft.dfs(entityset = es, target_dataframe_name = 'data',\n",
    "#                                       trans_primitives = ['add_numeric', 'multiply_numeric'])\n",
    "#\n",
    "# feature_matrix.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# groupby + shift(差值特征) + transform(count, mean, max, min, skew)\n",
    "\n",
    "# def get_shift_feats(data, gap_list=[1], gp_col=[], target_col=''):\n",
    "#     # gp_col可以是个列表进行多次分组，e.g. gp_col = [id1, id2]\n",
    "#     for gap in gap_list:\n",
    "#         # 后面减前面\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}'] = data.groupby(gp_col)[target_col].shift(-gap)\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}'] = data[''.join(gp_col)+f'{target_col}next{gap}'] - data[target_col]\n",
    "# \n",
    "#         # 前面减后面\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}'] = data.groupby(gp_col)[target_col].shift(+gap)\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}'] = data[''.join(gp_col)+f'{target_col}next{gap}'] - data[target_col]\n",
    "# \n",
    "# \n",
    "#         # 统计其不为nan的值\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}count'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}next{gap}'].transform('count')\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}count'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}prev{gap}'].transform('count')\n",
    "# \n",
    "#         # 统计其平均值\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}mean'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}next{gap}'].transform('mean')\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}mean'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}prev{gap}'].transform('mean')\n",
    "# \n",
    "#         # 统计其最大值\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}max'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}next{gap}'].transform('max')\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}max'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}prev{gap}'].transform('max')\n",
    "# \n",
    "#         # 统计其最小值\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}min'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}next{gap}'].transform('min')\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}min'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}prev{gap}'].transform('min')\n",
    "# \n",
    "#         # 统计其skew值\n",
    "#         data[''.join(gp_col)+f'{target_col}next{gap}skew'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}next{gap}'].transform('skew')\n",
    "#         data[''.join(gp_col)+f'{target_col}prev{gap}skew'] = data.groupby(gp_col)[''.join(gp_col)+f'{target_col}prev{gap}'].transform('skew')\n",
    "# \n",
    "#     return data\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "# gp_tg_cols = [(['推料器启停'], '给水流量'),\n",
    "#               (['推料器启停'], '主蒸汽流量')]\n",
    "# \n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# for col in tqdm(gp_tg_cols):\n",
    "#     data = get_shift_feats(data, gap_list=list(range(1, 10)), gp_col=col[0], target_col=col[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# data.columns = [str(i) for i in data.columns]\n",
    "# for i in data.columns:\n",
    "#     print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:07<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 53.34 Mb (73.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "# # 内存压缩\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in tqdm(df.columns):\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (\n",
    "                start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "# 压缩使用内存\n",
    "# 由于数据比较大，所以合理的压缩内存节省空间尤为的重要\n",
    "# 使用reduce_mem_usage函数可以压缩近70%的内存占有。\n",
    "data = reduce_mem_usage(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums features:  259\n"
     ]
    }
   ],
   "source": [
    "print('nums features: ', len(data.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "label = '推料器自动指令'\n",
    "test_data = data.tail(1800)\n",
    "train = data.iloc[:-1800, :]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "features = train.columns.drop(['时间', label]).tolist()\n",
    "train_x, train_y = train[features], train[label]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************  1 fold************************************\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60197\n",
      "[LightGBM] [Info] Number of data points in the train set: 80208, number of used features: 255\n",
      "[LightGBM] [Info] Start training from score 70.000000\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's rmse: 4.3598\tvalid_1's rmse: 4.33038\n",
      "[400]\ttraining's rmse: 3.42659\tvalid_1's rmse: 3.39811\n",
      "[600]\ttraining's rmse: 3.16131\tvalid_1's rmse: 3.12643\n",
      "[800]\ttraining's rmse: 2.6728\tvalid_1's rmse: 2.63813\n",
      "[1000]\ttraining's rmse: 2.24504\tvalid_1's rmse: 2.20423\n",
      "[1200]\ttraining's rmse: 2.09262\tvalid_1's rmse: 2.04213\n",
      "[1400]\ttraining's rmse: 1.9601\tvalid_1's rmse: 1.90752\n",
      "[1600]\ttraining's rmse: 1.84742\tvalid_1's rmse: 1.79612\n",
      "[1800]\ttraining's rmse: 1.768\tvalid_1's rmse: 1.71699\n",
      "[2000]\ttraining's rmse: 1.6107\tvalid_1's rmse: 1.59429\n",
      "[2200]\ttraining's rmse: 1.4538\tvalid_1's rmse: 1.48321\n",
      "[2400]\ttraining's rmse: 1.41728\tvalid_1's rmse: 1.45094\n",
      "[2600]\ttraining's rmse: 1.37184\tvalid_1's rmse: 1.41002\n",
      "[2800]\ttraining's rmse: 1.34155\tvalid_1's rmse: 1.38091\n",
      "[3000]\ttraining's rmse: 1.3121\tvalid_1's rmse: 1.35425\n",
      "[3200]\ttraining's rmse: 1.29255\tvalid_1's rmse: 1.33535\n",
      "[3400]\ttraining's rmse: 1.27344\tvalid_1's rmse: 1.31728\n",
      "[3600]\ttraining's rmse: 1.25189\tvalid_1's rmse: 1.29687\n",
      "[3800]\ttraining's rmse: 1.23388\tvalid_1's rmse: 1.27965\n",
      "[4000]\ttraining's rmse: 1.21228\tvalid_1's rmse: 1.25938\n",
      "[4200]\ttraining's rmse: 1.19589\tvalid_1's rmse: 1.24325\n",
      "[4400]\ttraining's rmse: 1.18425\tvalid_1's rmse: 1.23142\n",
      "[4600]\ttraining's rmse: 1.16453\tvalid_1's rmse: 1.21308\n",
      "[4800]\ttraining's rmse: 1.15138\tvalid_1's rmse: 1.20045\n",
      "[5000]\ttraining's rmse: 1.13761\tvalid_1's rmse: 1.18625\n",
      "[5200]\ttraining's rmse: 1.10896\tvalid_1's rmse: 1.15455\n",
      "[5400]\ttraining's rmse: 1.09537\tvalid_1's rmse: 1.14101\n",
      "[5600]\ttraining's rmse: 1.08459\tvalid_1's rmse: 1.13071\n",
      "[5800]\ttraining's rmse: 1.07533\tvalid_1's rmse: 1.12221\n",
      "[6000]\ttraining's rmse: 1.06726\tvalid_1's rmse: 1.11388\n",
      "[6200]\ttraining's rmse: 1.06072\tvalid_1's rmse: 1.10735\n",
      "[6400]\ttraining's rmse: 1.04809\tvalid_1's rmse: 1.09491\n",
      "[6600]\ttraining's rmse: 1.03891\tvalid_1's rmse: 1.08587\n",
      "[6800]\ttraining's rmse: 1.03002\tvalid_1's rmse: 1.0772\n",
      "[7000]\ttraining's rmse: 1.02351\tvalid_1's rmse: 1.07107\n",
      "[7200]\ttraining's rmse: 1.01514\tvalid_1's rmse: 1.06264\n",
      "[7400]\ttraining's rmse: 1.00918\tvalid_1's rmse: 1.05667\n",
      "[7600]\ttraining's rmse: 1.0017\tvalid_1's rmse: 1.04902\n",
      "[7800]\ttraining's rmse: 0.996031\tvalid_1's rmse: 1.04364\n",
      "[8000]\ttraining's rmse: 0.99193\tvalid_1's rmse: 1.03946\n",
      "[8200]\ttraining's rmse: 0.988374\tvalid_1's rmse: 1.03617\n",
      "[8400]\ttraining's rmse: 0.984056\tvalid_1's rmse: 1.03211\n",
      "[8600]\ttraining's rmse: 0.976292\tvalid_1's rmse: 1.02377\n",
      "[8800]\ttraining's rmse: 0.969441\tvalid_1's rmse: 1.01609\n",
      "[9000]\ttraining's rmse: 0.965066\tvalid_1's rmse: 1.0116\n",
      "[9200]\ttraining's rmse: 0.96142\tvalid_1's rmse: 1.00775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_12804/3839128937.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     31\u001B[0m     }\n\u001B[0;32m     32\u001B[0m     model = lgb.train(params, train_set=dtrain, num_boost_round=10000, early_stopping_rounds=1000, valid_sets=watchlist,\n\u001B[1;32m---> 33\u001B[1;33m                       verbose_eval=200)\n\u001B[0m\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\lightgbm\\engine.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    290\u001B[0m                                     evaluation_result_list=None))\n\u001B[0;32m    291\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 292\u001B[1;33m         \u001B[0mbooster\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    293\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    294\u001B[0m         \u001B[0mevaluation_result_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\lightgbm\\basic.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, train_set, fobj)\u001B[0m\n\u001B[0;32m   3021\u001B[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001B[0;32m   3022\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3023\u001B[1;33m                 ctypes.byref(is_finished)))\n\u001B[0m\u001B[0;32m   3024\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__is_predicted_cur_iter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;32mFalse\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__num_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3025\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mis_finished\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 交叉验证所使用的第三方库\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "test_x = test_data[features]\n",
    "test_lgb = np.zeros(test_x.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "    print('************************************  {} fold************************************'.format(str(i + 1)))\n",
    "    trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], \\\n",
    "                                 train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "    dtrain = lgb.Dataset(trn_x, label=trn_y)\n",
    "    dvalid = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "    watchlist = [dtrain, dvalid]\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'l2_root',\n",
    "        'learning_rate': 0.01,\n",
    "        'reg_alpha': 0.7,\n",
    "        'reg_lambda': 35,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'feature_fraction': 0.7,\n",
    "        \"random_seed\": 1,\n",
    "    }\n",
    "    model = lgb.train(params, train_set=dtrain, num_boost_round=10000, early_stopping_rounds=1000, valid_sets=watchlist,\n",
    "                      verbose_eval=200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    test_lgb += test_pred / kf.n_splits\n",
    "\n",
    "\n",
    "    print(\"Features importance...\")\n",
    "    gain = model.feature_importance('gain')\n",
    "    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n",
    "                             'split': model.feature_importance('split'),\n",
    "                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "    print('Top 50 features:\\n', feat_imp.head(50))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(test_lgb).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# sub = test_data[['时间','推料器启停']]\n",
    "# sub['lgb' + label] = test_lgb\n",
    "# sub.reset_index(inplace=True)\n",
    "# sub.columns = ['ID', 'Time', 'Aps', 'Ai']\n",
    "\n",
    "\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = list(range(1,1801))\n",
    "sub['Time'] = test_df['时间']\n",
    "sub['Aps'] = test_df['推料器启停'].astype(bool)\n",
    "sub['Ai'] = test_lgb\n",
    "\n",
    "sub.to_csv('./result_lgb.csv', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}